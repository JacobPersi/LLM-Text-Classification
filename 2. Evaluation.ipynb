{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re\n",
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryPredictionEvaluation:\n",
    "    def __init__(self, model_name):\n",
    "        self.model_name = model_name\n",
    "        self.model_folder = f\"./models/{model_name}\"\n",
    "        self.checkpoint = self.get_latest_checkpoint(self.model_folder)\n",
    "\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(self.checkpoint)\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(self.checkpoint)\n",
    "\n",
    "    def get_latest_checkpoint(self, base_folder):\n",
    "        checkpoints = [d for d in os.listdir(base_folder) if os.path.isdir(os.path.join(base_folder, d)) and \"checkpoint-\" in d]\n",
    "        checkpoint_numbers = [int(re.search(r'\\d+', cp).group()) for cp in checkpoints]\n",
    "\n",
    "        if not checkpoint_numbers:\n",
    "            raise ValueError(\"No checkpoints found in the specified folder.\")\n",
    "\n",
    "        latest_checkpoint_number = max(checkpoint_numbers)\n",
    "        latest_checkpoint = f\"checkpoint-{latest_checkpoint_number}\"\n",
    "        return os.path.join(base_folder, latest_checkpoint)\n",
    "\n",
    "    def evaluate(self):\n",
    "        print(\"Evaluating\", self.model_name + \"!\")\n",
    "        df = pd.read_csv(self.model_folder + '/validation_data.csv')\n",
    "\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "\n",
    "        for index, row in df.iterrows():\n",
    "            text = row['Response']\n",
    "            label = row['Level']\n",
    "            inputs = self.tokenizer(text, return_tensors=\"pt\")\n",
    "            with torch.no_grad():\n",
    "                logits = self.model(**inputs).logits\n",
    "                predicted_class_id = logits.argmax().item()\n",
    "                prediction = self.model.config.id2label[predicted_class_id]\n",
    "\n",
    "                y_true.append(label)\n",
    "                y_pred.append(prediction)\n",
    "        \n",
    "        encoded_y_true = [0 if label == \"Low\" else 1 for label in y_true]\n",
    "        encoded_y_pred = [0 if label == \"Low\" else 1 for label in y_pred]\n",
    "\n",
    "        # Mean accuracy\n",
    "        print(\"Mean Accuracy:\\n\\t\", metrics.accuracy_score(y_true, y_pred))\n",
    "\n",
    "        # Confusion matrix\n",
    "        print(\"Confusion Matrix:\\n\\t\", metrics.confusion_matrix(y_true, y_pred))\n",
    "\n",
    "        # F1 Score\n",
    "        print(\"F1 Score:\\n\\t\", metrics.f1_score(encoded_y_true, encoded_y_pred))\n",
    "\n",
    "        # Precision\n",
    "        print(\"Precision:\\n\\t\", metrics.precision_score(encoded_y_true, encoded_y_pred))\n",
    "\n",
    "        # Recall\n",
    "        print(\"Recall:\\n\\t\", metrics.recall_score(encoded_y_true, encoded_y_pred))\n",
    "\n",
    "        # ROC AUC Score\n",
    "        print(\"ROC AUC:\\n\\t\", metrics.roc_auc_score(encoded_y_true, encoded_y_pred))\n",
    "        \n",
    "        # Cohen's Kappa Score\n",
    "        print(\"Cohen's Kappa:\\n\\t\", metrics.cohen_kappa_score(y_true, y_pred))\n",
    "\n",
    "        print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Binary!\n",
      "Mean Accuracy:\n",
      "\t 0.9238095238095239\n",
      "Confusion Matrix:\n",
      "\t [[48  3]\n",
      " [ 5 49]]\n",
      "F1 Score:\n",
      "\t 0.923076923076923\n",
      "Precision:\n",
      "\t 0.9056603773584906\n",
      "Recall:\n",
      "\t 0.9411764705882353\n",
      "ROC AUC:\n",
      "\t 0.9242919389978214\n",
      "Cohen's Kappa:\n",
      "\t 0.8476605005440696\n",
      "\n",
      "\n",
      "\n",
      "Evaluating Emotion!\n",
      "Mean Accuracy:\n",
      "\t 0.8333333333333334\n",
      "Confusion Matrix:\n",
      "\t [[16  2]\n",
      " [ 4 14]]\n",
      "F1 Score:\n",
      "\t 0.8421052631578948\n",
      "Precision:\n",
      "\t 0.8\n",
      "Recall:\n",
      "\t 0.8888888888888888\n",
      "ROC AUC:\n",
      "\t 0.8333333333333334\n",
      "Cohen's Kappa:\n",
      "\t 0.6666666666666667\n",
      "\n",
      "\n",
      "\n",
      "Evaluating Social!\n",
      "Mean Accuracy:\n",
      "\t 0.7142857142857143\n",
      "Confusion Matrix:\n",
      "\t [[19  0]\n",
      " [10  6]]\n",
      "F1 Score:\n",
      "\t 0.7916666666666666\n",
      "Precision:\n",
      "\t 0.6551724137931034\n",
      "Recall:\n",
      "\t 1.0\n",
      "ROC AUC:\n",
      "\t 0.6875\n",
      "Cohen's Kappa:\n",
      "\t 0.39446366782006925\n",
      "\n",
      "\n",
      "\n",
      "Evaluating Motivation!\n",
      "Mean Accuracy:\n",
      "\t 0.4857142857142857\n",
      "Confusion Matrix:\n",
      "\t [[ 4 18]\n",
      " [ 0 13]]\n",
      "F1 Score:\n",
      "\t 0.3076923076923077\n",
      "Precision:\n",
      "\t 1.0\n",
      "Recall:\n",
      "\t 0.18181818181818182\n",
      "ROC AUC:\n",
      "\t 0.5909090909090909\n",
      "Cohen's Kappa:\n",
      "\t 0.1416893732970026\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize a TextClassifier instance for each dataset\n",
    "Binary_evaluator = BinaryPredictionEvaluation(\"Binary\")\n",
    "Emotion_evaluator = BinaryPredictionEvaluation(\"Emotion\")\n",
    "Social_evaluator = BinaryPredictionEvaluation(\"Social\")\n",
    "Motivation_evaluator = BinaryPredictionEvaluation(\"Motivation\")\n",
    "\n",
    "# Train each model\n",
    "Binary_evaluator.evaluate()\n",
    "Emotion_evaluator.evaluate()\n",
    "Social_evaluator.evaluate()\n",
    "Motivation_evaluator.evaluate()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
